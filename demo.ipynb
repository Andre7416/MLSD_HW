{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio torch Pillow numpy torchvision\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import v2\n",
    "from torch import nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, hidden_dim=256, chan_dim=32, normalize=nn.BatchNorm2d, activation=nn.GELU, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, chan_dim, kernel_size=5),\n",
    "            activation(),\n",
    "            normalize(chan_dim),\n",
    "            nn.Conv2d(chan_dim, chan_dim, kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            activation(),\n",
    "            normalize(chan_dim),\n",
    "            nn.Conv2d(chan_dim, 2 * chan_dim, kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            activation(),\n",
    "            normalize(2 * chan_dim),\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(18 * chan_dim, hidden_dim),\n",
    "            activation(),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(hidden_dim, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch, _, _, _ = x.shape\n",
    "        x = self.model(x)\n",
    "        x = x.reshape(batch, -1)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = CNN()\n",
    "model.load_state_dict(torch.load('weights.pt'))\n",
    "model.eval()\n",
    "\n",
    "def predict_image(img):\n",
    "    img = Image.fromarray(img.astype('uint8')).convert('L')\n",
    "    img_array = np.array(img) / 255.0\n",
    "    img_tensor = torch.FloatTensor(img_array).unsqueeze(0).unsqueeze(0)\n",
    "    img_tensor = v2.Resize((28, 28))(img_tensor)\n",
    "    img_tensor = v2.Grayscale()(img_tensor)\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        probs = torch.softmax(output, dim=-1)[0]\n",
    "        pred_class = torch.argmax(probs).item()\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    \n",
    "    ax1.imshow(img_array, cmap='gray')\n",
    "    ax1.set_title(f\"Предсказан класс: {pred_class}\")\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    ax2.bar(range(10), probs.numpy(), color='skyblue')\n",
    "    ax2.set_xticks(range(10))\n",
    "    ax2.set_xticklabels(list(range(10)), rotation=45)\n",
    "    ax2.set_title('Вероятности классов')\n",
    "    ax2.set_ylim(0, 1)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=predict_image,\n",
    "    inputs=gr.Image(label=\"Загрузите изображение символа\"),\n",
    "    outputs=gr.Plot(label=\"Результат классификации\"),\n",
    "    title=\"Классификатор KMNIST\",\n",
    "    description=\"Загрузите изображение японского символа для классификации\"\n",
    ")\n",
    "\n",
    "demo.launch(share=False, inline=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
